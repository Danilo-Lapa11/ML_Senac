{"cells":[{"cell_type":"markdown","metadata":{"id":"dGl5p5yNqJvg"},"source":["# Classificação de Imagens com o Dataset MNIST:"]},{"cell_type":"markdown","metadata":{"id":"VNE8NyH4qJvh"},"source":["Nesta seção faremos o \"Hello World\" do aprendizado de máquina profundo: treinar um modelo de aprendizado  para classificar corretamente dígitos escritos à mão."]},{"cell_type":"markdown","metadata":{"id":"ldgyw6yPqJvi"},"source":["## Objetivos"]},{"cell_type":"markdown","metadata":{"id":"HGIg-b9kqJvj"},"source":["* Entenda como o aprendizado profundo pode resolver problemas que os métodos de programação tradicionais não conseguem\n","* Saiba mais sobre o [conjunto de dados de dígitos manuscritos MNIST](http://yann.lecun.com/exdb/mnist/)\n","* Use a [API Keras](https://keras.io/) para carregar o conjunto de dados MNIST e prepará-lo para treinamento\n","* Crie uma rede neural simples para realizar classificação de imagens\n","* Treine a rede neural usando o conjunto de dados MNIST preparado\n","* Observe o desempenho da rede neural treinada"]},{"cell_type":"markdown","metadata":{"id":"vkO--8jjqJvl"},"source":["## O Problema: Classificação de Imagens"]},{"cell_type":"markdown","metadata":{"id":"kDh4mL8AqJvm"},"source":["Na programação tradicional, o programador é capaz de articular regras e condições em seu código que seu programa pode então usar para agir da maneira correta. Essa abordagem continua a funcionar excepcionalmente bem para uma grande variedade de problemas.\n","\n","A classificação de imagens, que pede a um programa para classificar corretamente uma imagem que nunca viu antes em sua classe correta, é quase impossível de ser resolvida com técnicas de programação tradicionais. Como poderia um programador definir as regras e condições para classificar corretamente uma enorme variedade de imagens, especialmente tendo em conta imagens que nunca viu?"]},{"cell_type":"markdown","metadata":{"id":"-odk3bcCqJvn"},"source":["## A solução: Deep Learning"]},{"cell_type":"markdown","metadata":{"id":"bF6wVqldqJvo"},"source":["O aprendizado profundo é excelente no reconhecimento de padrões por tentativa e erro. Ao treinar uma rede neural profunda com dados suficientes e fornecer à rede feedback sobre seu desempenho por meio de treinamento, a rede pode identificar, através de uma enorme quantidade de iterações, seu próprio conjunto de condições pelas quais ela pode agir da maneira correta."]},{"cell_type":"markdown","metadata":{"id":"7IkJeSTgqJvp"},"source":["## O Dataset MNIST"]},{"cell_type":"markdown","metadata":{"id":"KnpjOarbqJvr"},"source":["Na história do aprendizado profundo, a classificação precisa de imagens do [conjunto de dados MNIST](http://yann.lecun.com/exdb/mnist/), uma coleção de 70.000 imagens em tons de cinza de dígitos manuscritos de 0 a 9, foi uma tarefa difícil. grande desenvolvimento. Embora hoje o problema seja considerado trivial, fazer classificação de imagens com MNIST tornou-se uma espécie de “Olá Mundo” para aprendizagem profunda."]},{"cell_type":"markdown","metadata":{"id":"tSGe7a7lqJvr"},"source":["Aqui estão 40 das imagens incluídas no Dataset MNIST:"]},{"cell_type":"markdown","metadata":{"id":"vmZzwyLOqJvs"},"source":["![picture](https://drive.google.com/uc?id=1PzAr3emcnpuV6kkXXUshpMWkEnOtvW0D)"]},{"cell_type":"markdown","metadata":{"id":"JRnogAN0qJvt"},"source":["## Treinando e Validando Dados e Rótulos"]},{"cell_type":"markdown","metadata":{"id":"VrwOpVd5qJvu"},"source":["Ao trabalhar com imagens para aprendizado profundo, precisamos das próprias imagens, geralmente denotadas como `X`, e também dos [rótulos](https://developers.google.com/machine-learning/glossary#label) corretos para elas. imagens, geralmente denotadas como `Y`. Além disso, precisamos de valores `X` e `Y` para *treinar* o modelo e, em seguida, um conjunto separado de valores `X` e `Y` para *validar* o desempenho do modelo após ele ter sido treinado. Portanto, precisamos de 4 segmentos de dados para o conjunto de dados MNIST:\n","\n","1. `x_train`: Imagens usadas para treinar a rede neural\n","2. `y_train`: rótulos corretos para as imagens `x_train`, usados para avaliar as previsões do modelo durante o treinamento\n","3. `x_valid`: Imagens reservadas para validação do desempenho do modelo após seu treinamento\n","4. `y_valid`: rótulos corretos para as imagens `x_valid`, usados para avaliar as previsões do modelo após ele ter sido treinado\n","\n","O processo de preparação de dados para análise é denominado [Engenharia de Dados](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7). Para saber mais sobre as diferenças entre dados de treinamento e dados de validação (bem como dados de teste), confira [este artigo](https://machinelearningmastery.com/difference-test-validation-datasets/) de Jason Brownlee."]},{"cell_type":"markdown","metadata":{"id":"VIEmLGONqJvv"},"source":["## Carregando os dados na memória (with Keras)"]},{"cell_type":"markdown","metadata":{"id":"dA7S-JHQqJvw"},"source":["Existem muitas [estruturas de aprendizagem profunda](https://developer.nvidia.com/deep-learning-frameworks), cada uma com seus próprios méritos. Neste workshop trabalharemos com [Tensorflow 2](https://www.tensorflow.org/tutorials/quickstart/beginner) e especificamente com a [API Keras](https://keras.io/). Keras tem muitas funções úteis integradas projetadas para tarefas de visão computacional. É também uma escolha legítima para aprendizagem profunda em um ambiente profissional devido à sua [legibilidade](https://blog.pragmaticengineer.com/readable-code/) e eficiência, embora não esteja sozinho nesse aspecto, e é vale a pena investigar uma variedade de estruturas ao iniciar um projeto de aprendizagem profunda.\n","\n","Um dos muitos recursos úteis que Keras oferece são módulos contendo muitos métodos auxiliares para [muitos conjuntos de dados comuns](https://www.tensorflow.org/api_docs/python/tf/keras/datasets), incluindo MNIST.\n","\n","Começaremos carregando o módulo do conjunto de dados Keras para MNIST:"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2884,"status":"ok","timestamp":1698755919806,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"_EE3VKHEqJvx"},"outputs":[],"source":["from tensorflow.keras.datasets import mnist"]},{"cell_type":"markdown","metadata":{"id":"OkMrMwr0qJvy"},"source":["Com o módulo `mnist`, podemos carregar facilmente os dados MNIST, já particionados em imagens e rótulos para treinamento e validação:"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698755919806,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"0c1BT_bUqJvz"},"outputs":[],"source":["# the data, split between train and validation sets\n","(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"]},{"cell_type":"markdown","metadata":{"id":"3E5CC_MIqJv0"},"source":["## Explorando a base de dados MNIST:"]},{"cell_type":"markdown","metadata":{"id":"92nLWhdDqJv0"},"source":["Afirmamos acima que o conjunto de dados MNIST continha 70.000 imagens em tons de cinza de dígitos manuscritos. Ao executar as células a seguir, podemos ver que Keras particionou 60.000 dessas imagens para treinamento e 10.000 para validação (após o treinamento), e também que cada imagem em si é um array 2D com dimensões 28x28:"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698755919806,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"2qIRPJu3qJv1","outputId":"bc21fbf4-453d-448f-fbff-a2696065ac1f"},"outputs":[{"data":{"text/plain":["(60000, 28, 28)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698755919806,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"AyBRhHHdqJv1","outputId":"56878969-2000-431d-f40d-092fe757cdb0"},"outputs":[{"data":{"text/plain":["(10000, 28, 28)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["x_valid.shape"]},{"cell_type":"markdown","metadata":{"id":"jJkBMHeOqJv2"},"source":["Além disso, podemos ver que essas imagens 28x28 são representadas como uma coleção de valores inteiros de 8 bits sem sinal entre 0 e 255, os valores correspondentes ao valor da escala de cinza de um pixel onde `0` é preto, `255` é branco e todos os outros os valores estão entre:"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698755919806,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"AKWqXDgRqJv2","outputId":"482666ad-d37c-4976-ddba-6dc618c95003"},"outputs":[{"data":{"text/plain":["dtype('uint8')"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["x_train.dtype"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1698755919806,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"3Tt8GkLnqJv3","outputId":"beb5222d-129d-426a-e2a4-ae4e1cbaef1c"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["x_train.min()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698755919806,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"V37W8JDBqJv3","outputId":"6db591b9-cf5d-4093-ef63-f2787b4771e2"},"outputs":[{"data":{"text/plain":["255"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["x_train.max()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698755919806,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"5BKF0NWLqJv4","outputId":"553dae5e-1bd1-42a1-a65c-2c1217a39da3"},"outputs":[{"data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n","         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n","        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n","        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n","        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n","        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n","         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n","        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n","        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n","        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n","        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n","        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n","        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n","        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n","         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["x_train[0]"]},{"cell_type":"markdown","metadata":{"id":"WUWmptn7qJv4"},"source":["Usando [Matplotlib](https://matplotlib.org/), podemos renderizar uma destas imagens em tons de cinza em nosso conjunto de dados:"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"elapsed":521,"status":"ok","timestamp":1698755920322,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"urmiJvWuqJv5","outputId":"46d09619-1cfe-4021-d360-7f289ea65ca7"},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x7d2631dcd0c0>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","image = x_train[0]\n","plt.imshow(image, cmap='gray')"]},{"cell_type":"markdown","metadata":{"id":"RK6-LoiDqJv5"},"source":["Desta forma podemos ver agora que esta é uma imagem de 28x28 pixels de um 5. Ou é um 3? A resposta está nos dados `y_train`, que contém rótulos corretos para os dados. Vamos dar uma olhada:"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1698755920322,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"OgI7Vx0GqJv5","outputId":"6b6f1983-6f64-4457-af1b-c4d2638ecb65"},"outputs":[{"data":{"text/plain":["5"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["y_train[0]"]},{"cell_type":"markdown","metadata":{"id":"MVJ4BKzGqJv6"},"source":["## Preparando os dados para treino"]},{"cell_type":"markdown","metadata":{"id":"pxdbMenlqJv6"},"source":["No deep learning, é comum que os dados precisem ser transformados para ficarem no estado ideal para treinamento. Para este problema específico de classificação de imagens, existem 3 tarefas que devemos realizar com os dados na preparação para o treinamento:\n","1. Achate os dados da imagem para simplificar a entrada da imagem no modelo\n","2. Normalize os dados da imagem, para facilitar o trabalho com os valores de entrada da imagem para o modelo\n","3. Categorize os rótulos, para facilitar o trabalho com os valores dos rótulos para o modelo"]},{"cell_type":"markdown","metadata":{"id":"XNVi5wWaqJv7"},"source":["### (Flattening )Achatando os dados da imagem"]},{"cell_type":"markdown","metadata":{"id":"hTgC9PDrqJv7"},"source":["Embora seja possível para um modelo de aprendizagem profunda aceitar uma imagem bidimensional (no nosso caso 28x28 pixels), vamos simplificar as coisas para começar e [remodelar](https://www.tensorflow.org/api_docs/python /tf/reshape) cada imagem em uma única matriz de 784 pixels contínuos (nota: 28x28 = 784). Isso também é chamado de achatamento da imagem.\n","\n","Aqui fazemos isso usando o método auxiliar `reshape`:"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1698755920322,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"nQbBGKW1qJv8"},"outputs":[],"source":["x_train = x_train.reshape(60000, 784)\n","x_valid = x_valid.reshape(10000, 784)"]},{"cell_type":"markdown","metadata":{"id":"YrJOOdKwqJv8"},"source":["Podemos confirmar que os dados da imagem foram remodelados e agora são uma coleção de matrizes 1D contendo valores de 784 pixels cada:"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1698755920322,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"Dxt3CSxDqJv9","outputId":"1a39b458-b11d-4b7e-d82e-b92cd7d8d07a"},"outputs":[{"data":{"text/plain":["(60000, 784)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698755920322,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"gnojlFbFqJv9","outputId":"2bbe70bb-fc93-4829-eeac-40ab59075cea"},"outputs":[{"data":{"text/plain":["array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n","       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n","       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n","       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n","       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n","       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n","       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n","       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n","       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n","       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n","       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n","       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n","       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0], dtype=uint8)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["x_train[0]"]},{"cell_type":"markdown","metadata":{"id":"263F9RjfqJv-"},"source":["### Normalizando (scaling) os dados das imagens"]},{"cell_type":"markdown","metadata":{"id":"pyTMKcFSqJv-"},"source":["Os modelos de aprendizagem profunda são melhores para lidar com números de ponto flutuante entre 0 e 1 (mais sobre este tópico posteriormente). A conversão de valores inteiros em valores de ponto flutuante entre 0 e 1 é chamada de [normalização](https://developers.google.com/machine-learning/glossary#normalization). Uma abordagem simples que adotaremos aqui para normalizar os dados será para dividir todos os valores de pixel (que, se você se lembra, estão entre 0 e 255) por 255:"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698755920323,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"x14JtL03qJv-"},"outputs":[],"source":["x_train = x_train / 255\n","x_valid = x_valid / 255"]},{"cell_type":"markdown","metadata":{"id":"HCONUqYwqJv_"},"source":["Agora podemos ver que os valores são todos valores de ponto flutuante entre `0.0` e `1.0`:"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698755920323,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"UtQXDygWqJv_","outputId":"0f0f1cc4-7b00-458a-f688-b7f09b73f400"},"outputs":[{"data":{"text/plain":["dtype('float64')"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["x_train.dtype"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698755920323,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"nQE7uNjIqJwA","outputId":"569db840-6a68-4800-c07e-06e24d52d103"},"outputs":[{"data":{"text/plain":["0.0"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["x_train.min()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698755920323,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"0Eb5NPhYqJwA","outputId":"0686183c-c462-4b3a-f7f3-05921083facc"},"outputs":[{"data":{"text/plain":["1.0"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["x_train.max()"]},{"cell_type":"markdown","metadata":{"id":"UF4trIpCqJwB"},"source":["### Encoding categórico"]},{"cell_type":"markdown","metadata":{"id":"RwfbMFCNqJwB"},"source":["Considere por um momento, se perguntássemos: quanto é 7 - 2? Afirmar que a resposta foi 4 está mais próximo do que afirmar que a resposta foi 9. Porém, para este problema de classificação de imagens, não queremos que a rede neural aprenda esse tipo de raciocínio: queremos apenas que ela selecione a categoria correta, e entenda que se tivermos uma imagem do número 5, adivinhar 4 é tão ruim quanto adivinhar 9.\n","\n","Da forma como estão, os rótulos das imagens são números inteiros entre 0 e 9. Como esses valores representam um intervalo numérico, o modelo pode tentar tirar algumas conclusões sobre seu desempenho com base em quão próximo da categoria numérica correta ele estima.\n","\n","Portanto, faremos algo com nossos dados chamado codificação categórica. Esse tipo de transformação modifica os dados para que cada valor seja uma coleção de todas as categorias possíveis, com a categoria real em que esse valor específico é definida como verdadeira.\n","\n","Como exemplo simples, considere se tivéssemos 3 categorias: vermelho, azul e verde. Para uma determinada cor, 2 dessas categorias seriam falsas e a outra seria verdadeira:"]},{"cell_type":"markdown","metadata":{"id":"OcFlUDYIqJwC"},"source":["|Actual Color| Is Red? | Is Blue? | Is Green?|\n","|------------|---------|----------|----------|\n","|Red|True|False|False|\n","|Green|False|False|True|\n","|Blue|False|True|False|\n","|Green|False|False|True|"]},{"cell_type":"markdown","metadata":{"id":"pVUier6MqJwC"},"source":["Em vez de usar \"True\" ou \"False\", poderíamos representar o mesmo usando binário, 0 ou 1:"]},{"cell_type":"markdown","metadata":{"id":"MXvIw-kLqJwC"},"source":["|Actual Color| Is Red? | Is Blue? | Is Green?|\n","|------------|---------|----------|----------|\n","|Red|1|0|0|\n","|Green|0|0|1|\n","|Blue|0|1|0|\n","|Green|0|0|1|"]},{"cell_type":"markdown","metadata":{"id":"N9cJSApXqJwD"},"source":["Isto é a codificação categórica, transformando valores que se pretendem entender como rótulos categóricos numa representação que torna explícita ao modelo a sua natureza categórica. Assim, se estivéssemos usando esses valores para treinamento, converteríamos..."]},{"cell_type":"markdown","metadata":{"id":"M34k5iPNqJwD"},"source":["```python\n","values = ['red, green, blue, green']\n","```"]},{"cell_type":"markdown","metadata":{"id":"IUuYXVSBqJwE"},"source":["... que uma rede neural teria muita dificuldade em entender, em vez de:"]},{"cell_type":"markdown","metadata":{"id":"3_ODF0eaqJwE"},"source":["```python\n","values = [\n","    [1, 0, 0],\n","    [0, 0, 1],\n","    [0, 1, 0],\n","    [0, 0, 1]\n","]\n","```"]},{"cell_type":"markdown","metadata":{"id":"bLoI6_v5qJwF"},"source":["### Categorically Encoding the Labels"]},{"cell_type":"markdown","metadata":{"id":"0lIxJsyWqJwF"},"source":["Keras fornece um utilitário para [codificar valores categoricamente](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical), e aqui o usamos para realizar codificação categórica para rótulos de treinamento e validação :"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698755920323,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"j76kJbvAqJwG"},"outputs":[],"source":["import keras\n","num_categories = 10\n","\n","y_train = keras.utils.to_categorical(y_train, num_categories)\n","y_valid = keras.utils.to_categorical(y_valid, num_categories)"]},{"cell_type":"markdown","metadata":{"id":"texhvut4qJwG"},"source":["Aqui estão os primeiros 10 valores dos rótulos de treinamento, que você pode ver que agora foram codificados categoricamente:"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1698755920323,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"C8lgM1-6qJwG","outputId":"9764ce9d-dc79-4b45-f7d8-e44d53a69040"},"outputs":[{"data":{"text/plain":["array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["y_train[0:9]"]},{"cell_type":"markdown","metadata":{"id":"onpoqyDGqJwH"},"source":["## Criando o modelo"]},{"cell_type":"markdown","metadata":{"id":"xwvKA9tWqJwH"},"source":["Com os dados preparados para treinamento, agora é hora de criar o modelo que treinaremos com os dados. Este primeiro modelo básico será composto por várias *camadas* e será composto por 3 partes principais:\n","\n","1. Uma camada de entrada, que receberá dados em algum formato esperado\n","2. Várias [camadas ocultas](https://developers.google.com/machine-learning/glossary#hidden-layer), cada uma composta por muitos *neurônios*. Cada [neurônio](https://developers.google.com/machine-learning/glossary#neuron) terá a capacidade de afetar a estimativa da rede com seus *pesos*, que são valores que serão atualizados ao longo de muitas iterações conforme o rede recebe feedback sobre seu desempenho e aprende\n","3. Uma camada de saída, que representará a estimativa da rede para uma determinada imagem"]},{"cell_type":"markdown","metadata":{"id":"u6oq98t1qJwI"},"source":["### Instanciando o modelo"]},{"cell_type":"markdown","metadata":{"id":"QbO1qOYAqJwI"},"source":["Para começar, usaremos a classe de modelo [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) de Keras para instanciar uma instância de um modelo que terá uma série de camadas nas quais os dados serão passe em sequência:"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":1790,"status":"ok","timestamp":1698755922106,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"kCeGCrlRqJwI"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","\n","model = Sequential()"]},{"cell_type":"markdown","metadata":{"id":"z41JAZjMqJwJ"},"source":["### Criando a camada de entrada"]},{"cell_type":"markdown","metadata":{"id":"xZG6iHQOqJwJ"},"source":["A seguir, adicionaremos a camada de entrada. Esta camada será *densamente conectada*, o que significa que cada neurônio nela e seus pesos afetarão todos os neurônios da próxima camada. Para fazer isso com Keras, usamos a classe de camada [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) de Keras."]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698755922106,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"AUXpoAXPqJwK"},"outputs":[],"source":["from tensorflow.keras.layers import Dense"]},{"cell_type":"markdown","metadata":{"id":"hzuKNSxDqJwK"},"source":["O argumento `units` especifica o número de neurônios na camada. Usaremos `512` que escolhemos na experimentação. Escolher o número correto de neurônios é o que coloca a “ciência” na “ciência de dados”, pois se trata de capturar a complexidade estatística do conjunto de dados. Experimente brincar com esse valor mais tarde para ver como ele afeta o treinamento e para começar a desenvolver uma noção do que esse número significa.\n","\n","Aprenderemos mais sobre funções de ativação mais tarde, mas por enquanto usaremos a função de ativação `relu`, que, em resumo, ajudará nossa rede a aprender como fazer suposições mais sofisticadas sobre os dados do que se fosse necessário fazer suposições baseadas em em alguma função estritamente linear.\n","\n","O valor `input_shape` especifica a forma dos dados recebidos que em nossa situação é uma matriz 1D de 784 valores:"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698755922106,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"h1w36GpsqJwK"},"outputs":[],"source":["model.add(Dense(units=512, activation='relu', input_shape=(784,)))"]},{"cell_type":"markdown","metadata":{"id":"TRJQcuZZqJwL"},"source":["### Criando as camadas intermediárias"]},{"cell_type":"markdown","metadata":{"id":"RaMRHxSgqJwL"},"source":["Agora adicionaremos uma camada adicional densamente conectada. Novamente, muito mais será dito sobre isso posteriormente, mas por enquanto saiba que essas camadas fornecem à rede mais parâmetros para contribuir com suas suposições e, portanto, oportunidades mais sutis para um aprendizado preciso:"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698755922106,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"oLs_xkK-qJwM"},"outputs":[],"source":["model.add(Dense(units = 512, activation='relu'))"]},{"cell_type":"markdown","metadata":{"id":"-x_1IPvbqJwM"},"source":["### Criando a camada de saída"]},{"cell_type":"markdown","metadata":{"id":"OvOmgJzeqJwM"},"source":["Finalmente, adicionaremos uma camada de saída. Esta camada usa a função de ativação `softmax` que resultará em cada um dos valores da camada sendo uma probabilidade entre 0 e 1 e resultará em todas as saídas da camada somando 1. Neste caso, como a rede deve fazer um suponha que uma única imagem pertença a 1 das 10 categorias possíveis, haverá 10 resultados. Cada saída fornece a estimativa do modelo (uma probabilidade) de que a imagem pertence a essa classe específica:"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698755922107,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"klVnw2HZqJwN"},"outputs":[],"source":["model.add(Dense(units = 10, activation='softmax')) # softmax retorna valores entre 0 - 1"]},{"cell_type":"markdown","metadata":{"id":"6rRXIj6TqJwN"},"source":["### Sumarizando o Modelo"]},{"cell_type":"markdown","metadata":{"id":"hzLyvPh1qJwO"},"source":["Keras fornece o método de instância de modelo [summary](https://www.tensorflow.org/api_docs/python/tf/summary) que imprimirá um resumo legível de um modelo:"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698755922107,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"mvEs89JOqJwO","outputId":"291d7821-8f5e-4c4e-b5f9-b7dc17571042"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 512)               401920    \n","                                                                 \n"," dense_1 (Dense)             (None, 512)               262656    \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 669706 (2.55 MB)\n","Trainable params: 669706 (2.55 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"UkP9XhCuqJwP"},"source":["Observe o número de parâmetros treináveis. Cada um deles pode ser ajustado durante o treinamento e contribuirá para as suposições do modelo treinado."]},{"cell_type":"markdown","metadata":{"id":"cOBZkDoFqJwP"},"source":["### Compilando o Modelo"]},{"cell_type":"markdown","metadata":{"id":"P1-zgdiHqJwP"},"source":["Novamente, mais detalhes estão a seguir, mas a etapa final que precisamos realizar antes de podermos realmente treinar nosso modelo com dados é [compilar](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential #compilar). Aqui especificamos uma [função de perda](https://developers.google.com/machine-learning/glossary#loss) que será usada para o modelo entender seu desempenho durante o treinamento. Também especificamos que gostaríamos de rastrear a `precisão` enquanto o modelo treina:"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1698755922107,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"5QdhjvDXqJwP"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"nBC2MVj1qJwQ"},"source":["## Treinando o Modelo"]},{"cell_type":"markdown","metadata":{"id":"2bFjh5hDqJwQ"},"source":["Agora que preparamos os dados de treinamento e validação e um modelo, é hora de treinar nosso modelo com nossos dados de treinamento e verificá-lo com seus dados de validação.\n","\n","“Treinar um modelo com dados” também é frequentemente chamado de “ajustar um modelo aos dados”. Dito desta última forma, destaca que a forma do modelo muda ao longo do tempo para compreender com mais precisão os dados que lhe são fornecidos.\n","\n","Ao ajustar (treinar) um modelo com Keras, usamos o método [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) do modelo. Ele espera os seguintes argumentos:\n","\n","* Os dados de treinamento\n","* Os rótulos dos dados de treinamento\n","* O número de vezes que ele deve treinar em todo o conjunto de dados de treinamento (chamado de *época*)\n","* Os dados de validação ou teste e seus rótulos\n","\n","Execute a célula abaixo para treinar o modelo. Discutiremos seu resultado após a conclusão do treinamento:"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69799,"status":"ok","timestamp":1698756893997,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"eDTuiKREqJwQ","outputId":"91a4db99-9f44-4bd3-d16c-aedf7f8566be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.1260 - val_accuracy: 0.9839\n","Epoch 2/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.1358 - val_accuracy: 0.9833\n","Epoch 3/10\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1482 - val_accuracy: 0.9825\n","Epoch 4/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1241 - val_accuracy: 0.9844\n","Epoch 5/10\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1450 - val_accuracy: 0.9842\n","Epoch 6/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1420 - val_accuracy: 0.9835\n","Epoch 7/10\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1456 - val_accuracy: 0.9835\n","Epoch 8/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1438 - val_accuracy: 0.9833\n","Epoch 9/10\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1497 - val_accuracy: 0.9846\n","Epoch 10/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1435 - val_accuracy: 0.9844\n"]}],"source":["\n","history = model.fit(\n","      x_train, y_train, epochs=10, verbose=1, validation_data=(x_valid, y_valid)\n",")"]},{"cell_type":"markdown","metadata":{"id":"EZIzdTxuqJwQ"},"source":["### Observando a Acurácia"]},{"cell_type":"markdown","metadata":{"id":"tE0XrpLwqJwR"},"source":["Para cada uma das 5 épocas, observe as pontuações de `precisão` e `val_accuracy`. `precisão` indica o desempenho do modelo para a época em todos os dados de treinamento. `val_accuracy` indica o desempenho do modelo nos dados de validação, que, se você se lembra, não foram usados ​​para treinar o modelo."]},{"cell_type":"markdown","metadata":{"id":"NWz6v03OqJwR"},"source":["O modelo se saiu muito bem! A precisão atingiu rapidamente perto de 100%, assim como a precisão da validação. Agora temos um modelo que pode ser usado para detectar e classificar com precisão imagens escritas à mão.\n","\n","O próximo passo seria usar este modelo para classificar novas imagens manuscritas ainda não vistas. Isso é chamado de [inferência](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/). Exploraremos o processo de inferência em um exercício posterior."]},{"cell_type":"markdown","metadata":{"id":"FQFOlVO2qJwR"},"source":["## Summary"]},{"cell_type":"markdown","metadata":{"id":"PZWTQCE3qJwR"},"source":["Vale a pena reservar um momento para apreciar o que fizemos aqui. Historicamente, os sistemas especialistas que foram construídos para realizar esse tipo de tarefa eram extremamente complicados, e as pessoas passaram suas carreiras construindo-os (confira as referências na [página oficial do MNIST](http://yann.lecun.com/exdb/ mnist/) e os marcos dos anos em que foram alcançados).\n","\n","O MNIST não é útil apenas por sua influência histórica na Visão Computacional, mas também é um ótimo [referência](http://www.cs.toronto.edu/~serailhydra/publications/tbd-iiswc18.pdf) e ferramenta de depuração. Está tendo problemas para fazer funcionar uma nova arquitetura sofisticada de aprendizado de máquina? Verifique com o MNIST. Se não conseguir aprender neste conjunto de dados, é provável que não aprenda em imagens e conjuntos de dados mais complicados."]},{"cell_type":"markdown","metadata":{"id":"FGjTyqNaqJwR"},"source":["## Clear the Memory"]},{"cell_type":"markdown","metadata":{"id":"qp5s_sAuqJwS"},"source":["Before moving on, please execute the following cell to clear up the GPU memory. This is required to move on to the next notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1698755941557,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"r6zYkY7bqJwS"},"outputs":[],"source":["# import IPython\n","# app = IPython.Application.instance()\n","# app.kernel.do_shutdown(True)"]},{"cell_type":"markdown","metadata":{"id":"dUWncNl4qJwS"},"source":["## Next"]},{"cell_type":"markdown","metadata":{"id":"yDcn_JmfqJwS"},"source":["In this section you learned how to build and train a simple neural network for image classification. In the next section, you will be asked to build your own neural network and perform data preparation to solve a different image classification problem."]},{"cell_type":"markdown","metadata":{"id":"fyHAezDuqJwT"},"source":["## ☆ Bonus Exercise ☆\n","\n","Have time to spare? In the next section, we will talk about how we arrived at some of the numbers above, but we can try imagining what it was like to be a researcher developing the techniques commonly used today.\n","\n","Ultimately, each neuron is trying to fit a line to some data. Below, we have some datapoints and a randomly drawn line using the equation [y = mx + b](https://www.mathsisfun.com/equation_of_line.html).\n","\n","Try changing the `m` and the `b` in order to find the lowest possible loss. How did you find the best line? Can you make a program to follow your strategy?"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1698755941557,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"7Qr5OkIcqJwT"},"outputs":[],"source":["import numpy as np\n","from numpy.polynomial.polynomial import polyfit\n","import matplotlib.pyplot as plt\n","\n","m = -2  # -2 to start, change me please\n","b = 40  # 40 to start, change me please\n","\n","# Sample data\n","x = np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n","y = np.array([10, 20, 25, 30, 40, 45, 40, 50, 60, 55])\n","y_hat = x * m + b\n","\n","plt.plot(x, y, '.')\n","plt.plot(x, y_hat, '-')\n","plt.show()\n","\n","print(\"Loss:\", np.sum((y - y_hat)**2)/len(x))"]},{"cell_type":"markdown","metadata":{"id":"NmK4BFhmqJwU"},"source":["Have an idea? Excellent! Please shut down the kernel before moving on."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1698755941557,"user":{"displayName":"Danilo Wanderley Lapa","userId":"10188901348740999986"},"user_tz":180},"id":"Kq-Kw97wqJwU"},"outputs":[],"source":["#import IPython\n","#app = IPython.Application.instance()\n","#app.kernel.do_shutdown(True)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
